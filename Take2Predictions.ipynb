{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Netflix Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = scipy.sparse.load_npz('sample_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_test = scipy.sparse.load_npz('sample_matrix_test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_value = np.load('test_value.npz')['arr_0']\n",
    "test_movie = np.load('test_movie.npz')['arr_0']\n",
    "test_user = np.load('test_user.npz')['arr_0']\n",
    "train_value = np.load('train_value.npz')['arr_0']\n",
    "train_movie = np.load('train_movie.npz')['arr_0']\n",
    "train_user = np.load('train_user.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features\n",
    "movie_avg = np.zeros(5000)\n",
    "movie_revs = np.zeros(5000)\n",
    "# movie_pos = np.zeros(5000)\n",
    "# movie_neg = np.zeros(5000)\n",
    "user_avg = np.zeros (10000)\n",
    "user_revs = np.zeros(10000)\n",
    "# user_pos = np.zeros(10000)\n",
    "# user_neg = np.zeros(10000)\n",
    "\n",
    "for i in range(5000):\n",
    "    movie_slice = ratings[i, :]\n",
    "    movie_avg[i] = csr_matrix.mean(movie_slice)\n",
    "    movie_revs[i] = csr_matrix.count_nonzero(movie_slice)\n",
    "#     count_neg = 0\n",
    "#     count_pos = 0\n",
    "#     for j in range(movie_slice.shape[1]):\n",
    "#         if movie_slice[0,j] > 4:\n",
    "#             count_pos+=1\n",
    "#         elif (movie_slice[0,j] < 2 and movie_slice[0,j] > 0):\n",
    "#             count_neg+=1\n",
    "#     movie_pos[i] = count_pos\n",
    "#     movie_neg[i] = count_neg\n",
    "    \n",
    "for i in range(10000):\n",
    "    user_slice = ratings[:, i]\n",
    "    user_avg[i] = csr_matrix.mean(user_slice)\n",
    "    user_revs[i] = csr_matrix.count_nonzero(user_slice)\n",
    "#     count_neg = 0\n",
    "#     count_pos = 0\n",
    "#     for j in range(user_slice.shape[1]):\n",
    "#         if user_slice[0,j] > 4:\n",
    "#             count_pos+=1\n",
    "#         elif (user_slice[0,j] < 2 and user_slice[0,j] > 0):\n",
    "#             count_neg+=1\n",
    "#     user_pos[i] = count_pos\n",
    "#     user_neg[i] = count_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Movie avg, user avg, # movie reviews, # user reviews, # positive movie reviews, # negative movie review\n",
    "# #positive user reiews, # negative user reviews\n",
    "movie_avg_train = np.zeros(len(train_value))\n",
    "user_avg_train = np.zeros(len(train_value))\n",
    "movie_revs_train = np.zeros(len(train_value))\n",
    "user_revs_train = np.zeros(len(train_value))\n",
    "# movie_pos_train = np.zeros(len(train_value))\n",
    "# user_pos_train = np.zeros(len(train_value))\n",
    "# movie_neg_train = np.zeros(len(train_value))\n",
    "# user_neg_train = np.zeros(len(train_value))\n",
    "\n",
    "for i in range(len(train_value)):\n",
    "    movie_avg_train[i] = movie_avg[train_movie[i]]\n",
    "    user_avg_train[i] = user_avg[train_user[i]]\n",
    "    movie_revs_train[i] = movie_revs[train_movie[i]]\n",
    "    user_revs_train[i] = user_revs[train_user[i]]\n",
    "#     movie_pos_train[i] = movie_pos[train_moive[i]]\n",
    "#     user_pos_train[i] = user_pos[train_user[i]]\n",
    "#     movie_neg_train[i] = movie_neg[train_movie[i]]\n",
    "#     user_neg_train[i] = user_neg[train_movie[i]]\n",
    "\n",
    "# features_train = np.vstack((movie_avg_train, user_avg_train, movie_revs_train, user_revs_train,\n",
    "#                             movie_pos_train, user_pos_train, movie_neg_train, user_neg_train)).T\n",
    "\n",
    "features_train = np.vstack((movie_avg_train, user_avg_train, movie_revs_train, user_revs_train)).T\n",
    "\n",
    "\n",
    "movie_avg_test = np.zeros(len(test_value))\n",
    "user_avg_test = np.zeros(len(test_value))\n",
    "movie_revs_test = np.zeros(len(test_value))\n",
    "user_revs_test = np.zeros(len(test_value))\n",
    "user_revs_test = np.zeros(len(test_value))\n",
    "# movie_pos_test = np.zeros(len(test_value))\n",
    "# user_pos_test = np.zeros(len(test_value))\n",
    "# movie_neg_test = np.zeros(len(test_value))\n",
    "# user_neg_test = np.zeros(len(test_value))\n",
    "\n",
    "for i in range(len(test_value)):\n",
    "    movie_avg_test[i] = movie_avg[test_movie[i]]\n",
    "    user_avg_test[i] = user_avg[test_user[i]]\n",
    "    movie_revs_test[i] = movie_revs[test_movie[i]]\n",
    "    user_revs_test[i] = user_revs[test_user[i]]\n",
    "#     movie_pos_test[i] = movie_pos[test_moive[i]]\n",
    "#     user_pos_test[i] = user_pos[test_user[i]]\n",
    "#     movie_neg_test[i] = movie_neg[test_movie[i]]\n",
    "#     user_neg_test[i] = user_neg[test_movie[i]]\n",
    "\n",
    "# features_test = np.vstack((movie_avg_test, user_avg_test, movie_revs_test, user_revs_test,\n",
    "#                            movie_pos_test, user_pos_test, movie_neg_test, user_neg_test)).T\n",
    "features_test = np.vstack((movie_avg_test, user_avg_test, movie_revs_test, user_revs_test)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(predictions, test_set):\n",
    "    summation = 0\n",
    "    for i in range(len(predictions)):\n",
    "        summation += (predictions[i] - test_set[i])**2\n",
    "    return summation/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE_non_zero(predictions, test_set):\n",
    "    summation = 0\n",
    "    non_zero = 0\n",
    "    for i in range(len(predictions)):\n",
    "        value = test_set[i]\n",
    "        if value > 0:\n",
    "            summation += (predictions[i] - value)**2\n",
    "            non_zero += 1\n",
    "    return summation/non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print MSE(movie_avg_test, test_value)\n",
    "print MSE(user_avg_test, test_value)\n",
    "print MSE_non_zero(movie_avg_test, test_value)\n",
    "print MSE_non_zero(user_avg_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(features_train, train_value)\n",
    "predictions = lr.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print lr.score(features_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(features_train, train_value)\n",
    "predictions = ridge.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ridge.score(features_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(features_train, train_value)\n",
    "predictions = lasso.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print lasso.score(features_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID    Year                          Name\n",
      "0   1  2003.0               Dinosaur Planet\n",
      "1   2  2004.0    Isle of Man TT 2004 Review\n",
      "2   3  1997.0                     Character\n",
      "3   4  1994.0  Paula Abdul's Get Up & Dance\n",
      "4   5  2004.0      The Rise and Fall of ECW\n"
     ]
    }
   ],
   "source": [
    "# This file consists of titles and release years associated with each ID\n",
    "movie_titles = pd.read_csv('movie_titles.txt', header = None, names = ['ID','Year','Name'])\n",
    "print(movie_titles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 10\n",
    "svd = TruncatedSVD(n_components = n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = svd.fit_transform(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "components = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "print Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=20, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusters = 20\n",
    "kmeans = KMeans(init='k-means++', n_init=10, n_clusters=clusters)\n",
    "kmeans.fit(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3890\n",
      "19\n",
      "42\n",
      "122\n",
      "5\n",
      "17\n",
      "18\n",
      "57\n",
      "27\n",
      "8\n",
      "54\n",
      "3\n",
      "562\n",
      "3\n",
      "4\n",
      "32\n",
      "116\n",
      "3\n",
      "13\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "labels = kmeans.labels_\n",
    "cluster_map = []\n",
    "for i in range(clusters):\n",
    "    cluster_map.append([])\n",
    "for i in range(5000):\n",
    "    cluster_map[labels[i]].append(i)\n",
    "for i in range(len(cluster_map)):\n",
    "    print len(cluster_map[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0one\n",
      "0two\n",
      "0\n",
      "32\n",
      "1000one\n",
      "1000two\n",
      "1000\n",
      "32\n",
      "2000one\n",
      "2000two\n",
      "2000\n",
      "32\n",
      "3000one\n",
      "3000two\n",
      "3000\n",
      "32\n",
      "4000one\n",
      "4000two\n",
      "4000\n",
      "32\n",
      "5000one\n",
      "5000two\n",
      "5000\n",
      "32\n",
      "6000one\n",
      "6000two\n",
      "6000\n",
      "32\n",
      "7000one\n",
      "7000two\n",
      "7000\n",
      "32\n",
      "8000one\n",
      "8000two\n",
      "8000\n",
      "3890\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-051fe375a5d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0muser_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mratings_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_movie\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msimilar_movies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0msimilar_users_avg_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_sum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0muser_cluster_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmap_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilar_users_avg_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;31m# [i, j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_single_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m             \u001b[0;31m# [i, 1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36m_get_single_element\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmajor_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;31m# can use np.add(..., where) from numpy 1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         return np.compress(minor_index == self.indices[start:end],\n\u001b[0m\u001b[1;32m    893\u001b[0m                            self.data[start:end]).sum(dtype=self.dtype)\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "user_cluster_map={}    \n",
    "\n",
    "similar_users_avg_train = np.zeros(len(train_value))\n",
    "\n",
    "for i in range(len(train_value)):\n",
    "    if i % 1000 == 0:\n",
    "        print str(i) + 'one'\n",
    "    user = train_user[i]\n",
    "    label = labels[train_movie[i]]\n",
    "    map_key = str(user) + ':' + str(label)\n",
    "    if i % 1000 == 0:\n",
    "        print str(i) + 'two'\n",
    "    if map_key in user_cluster_map:\n",
    "        if i % 1000 == 0:\n",
    "            print str(i) + \"if\"\n",
    "        similar_users_avg_train[i] = user_cluster_map[map_key]\n",
    "    else:\n",
    "        if i % 1000 == 0:\n",
    "            print i\n",
    "        user_sum = 0\n",
    "        similar_movies = cluster_map[label]\n",
    "        if i % 1000 == 0:\n",
    "            print len(similar_movies)\n",
    "        for j in range(len(similar_movies)):\n",
    "            user_sum += ratings_test[train_movie[similar_movies[j]],user]\n",
    "        similar_users_avg_train[i] = user_sum / len(similar_movies)\n",
    "        user_cluster_map[map_key] = similar_users_avg_train[i]\n",
    "\n",
    "similar_users_avg_test = np.zeros(len(test_value))\n",
    "\n",
    "for i in range(len(test_value)):\n",
    "    user = test_user[i]\n",
    "    label = labels[test_movie[i]]\n",
    "    map_key = str(user) + ':' + str(label)\n",
    "    if map_key in user_cluster_map:\n",
    "        similar_users_avg_test[i] = user_cluster_map[map_key]\n",
    "    else:\n",
    "        user_sum = 0\n",
    "        similar_movies = cluster_map[label]\n",
    "        for j in range(len(similar_movies)):\n",
    "            user_sum += ratings_test[test_movie[similar_movies[j]],user]\n",
    "        similar_users_avg_test[i] = user_sum / len(similar_movies)\n",
    "        user_cluster_map[map_key] = similar_users_avg_test[i]\n",
    "    \n",
    "    #average that the user rated similar movies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train_complex = similar_users_avg_train.T\n",
    "features_test_complex = similar_users_avg_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(features_train_complex, train_value)\n",
    "predictions = lr.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
