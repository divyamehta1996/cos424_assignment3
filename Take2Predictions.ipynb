{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Netflix Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = scipy.sparse.load_npz('sample_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_value = np.load('test_value.npz')['arr_0']\n",
    "test_movie = np.load('test_movie.npz')['arr_0']\n",
    "test_user = np.load('test_user.npz')['arr_0']\n",
    "train_value = np.load('train_value.npz')['arr_0']\n",
    "train_movie = np.load('train_movie.npz')['arr_0']\n",
    "train_user = np.load('train_user.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features\n",
    "movie_avg = np.zeros(5000)\n",
    "movie_revs = np.zeros(5000)\n",
    "user_avg = np.zeros (10000)\n",
    "user_revs = np.zeros(10000)\n",
    "for i in range(5000):\n",
    "    movie_slice = ratings[i, :]\n",
    "    movie_avg[i] = csr_matrix.mean(movie_slice)\n",
    "    movie_revs[i] = csr_matrix.count_nonzero(movie_slice)\n",
    "for i in range(10000):\n",
    "    user_slice = ratings[:, i]\n",
    "    user_avg[i] = csr_matrix.mean(user_slice)\n",
    "    user_revs[i] = csr_matrix.count_nonzero(user_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Movie avg, user avg, # movie reviews, # user reviews, # positive movie reviews, # negative movie review\n",
    "# #positive user reiews, # negative user reviews\n",
    "movie_avg_train = np.zeros(len(train_value))\n",
    "user_avg_train = np.zeros(len(train_value))\n",
    "movie_revs_train = np.zeros(len(train_value))\n",
    "user_revs_train = np.zeros(len(train_value))\n",
    "\n",
    "for i in range(len(train_value)):\n",
    "    movie_avg_train[i] = movie_avg[train_movie[i]]\n",
    "    user_avg_train[i] = user_avg[train_user[i]]\n",
    "    movie_revs_train[i] = movie_revs[train_movie[i]]\n",
    "    user_revs_train[i] = user_revs[train_user[i]]\n",
    "\n",
    "features_train = np.vstack((movie_avg_train, user_avg_train, movie_revs_train, user_revs_train)).T\n",
    "\n",
    "movie_avg_test = np.zeros(len(test_value))\n",
    "user_avg_test = np.zeros(len(test_value))\n",
    "movie_revs_test = np.zeros(len(test_value))\n",
    "user_revs_test = np.zeros(len(test_value))\n",
    "\n",
    "for i in range(len(test_value)):\n",
    "    movie_avg_test[i] = movie_avg[test_movie[i]]\n",
    "    user_avg_test[i] = user_avg[test_user[i]]\n",
    "    movie_revs_test[i] = movie_revs[test_movie[i]]\n",
    "    user_revs_test[i] = user_revs[test_user[i]]\n",
    "\n",
    "features_test = np.vstack((movie_avg_test, user_avg_test, movie_revs_test, user_revs_test)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(predictions, test_set):\n",
    "    summation = 0\n",
    "    for i in range(len(predictions)):\n",
    "        summation += (predictions[i] - test_set[i])**2\n",
    "    return summation/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE_non_zero(predictions, test_set):\n",
    "    summation = 0\n",
    "    non_zero = 0\n",
    "    for i in range(len(predictions)):\n",
    "        value = test_set[i]\n",
    "        if value > 0:\n",
    "            summation += (predictions[i] - value)**2\n",
    "            non_zero += 1\n",
    "    return summation/non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0307532696129\n",
      "0.0303709616256\n",
      "13.796825834\n",
      "13.4713849259\n"
     ]
    }
   ],
   "source": [
    "print MSE(movie_avg_test, test_value)\n",
    "print MSE(user_avg_test, test_value)\n",
    "print MSE_non_zero(movie_avg_test, test_value)\n",
    "print MSE_non_zero(user_avg_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(features_train, train_value)\n",
    "predictions = lr.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0513487103814\n"
     ]
    }
   ],
   "source": [
    "print lr.score(features_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0297568698712\n",
      "12.9444972069\n"
     ]
    }
   ],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(features_train, train_value)\n",
    "predictions = ridge.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0513486075259\n"
     ]
    }
   ],
   "source": [
    "print ridge.score(features_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0297568730932\n",
      "12.9445485675\n"
     ]
    }
   ],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(features_train, train_value)\n",
    "predictions = lasso.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030566601058\n",
      "13.9143903203\n"
     ]
    }
   ],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0255344179851\n"
     ]
    }
   ],
   "source": [
    "print lasso.score(features_test, test_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
