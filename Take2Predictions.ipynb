{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Netflix Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = scipy.sparse.load_npz('sample_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_test = scipy.sparse.load_npz('sample_matrix_test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_value = np.load('test_value.npz')['arr_0']\n",
    "test_movie = np.load('test_movie.npz')['arr_0']\n",
    "test_user = np.load('test_user.npz')['arr_0']\n",
    "train_value = np.load('train_value.npz')['arr_0']\n",
    "train_movie = np.load('train_movie.npz')['arr_0']\n",
    "train_user = np.load('train_user.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features\n",
    "movie_avg = np.zeros(5000)\n",
    "movie_revs = np.zeros(5000)\n",
    "# movie_pos = np.zeros(5000)\n",
    "# movie_neg = np.zeros(5000)\n",
    "user_avg = np.zeros (10000)\n",
    "user_revs = np.zeros(10000)\n",
    "# user_pos = np.zeros(10000)\n",
    "# user_neg = np.zeros(10000)\n",
    "\n",
    "for i in range(5000):\n",
    "    movie_slice = ratings[i, :]\n",
    "    movie_avg[i] = csr_matrix.mean(movie_slice)\n",
    "    movie_revs[i] = csr_matrix.count_nonzero(movie_slice)\n",
    "#     count_neg = 0\n",
    "#     count_pos = 0\n",
    "#     for j in range(movie_slice.shape[1]):\n",
    "#         if movie_slice[0,j] > 4:\n",
    "#             count_pos+=1\n",
    "#         elif (movie_slice[0,j] < 2 and movie_slice[0,j] > 0):\n",
    "#             count_neg+=1\n",
    "#     movie_pos[i] = count_pos\n",
    "#     movie_neg[i] = count_neg\n",
    "    \n",
    "for i in range(10000):\n",
    "    user_slice = ratings[:, i]\n",
    "    user_avg[i] = csr_matrix.mean(user_slice)\n",
    "    user_revs[i] = csr_matrix.count_nonzero(user_slice)\n",
    "#     count_neg = 0\n",
    "#     count_pos = 0\n",
    "#     for j in range(user_slice.shape[1]):\n",
    "#         if user_slice[0,j] > 4:\n",
    "#             count_pos+=1\n",
    "#         elif (user_slice[0,j] < 2 and user_slice[0,j] > 0):\n",
    "#             count_neg+=1\n",
    "#     user_pos[i] = count_pos\n",
    "#     user_neg[i] = count_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Movie avg, user avg, # movie reviews, # user reviews, # positive movie reviews, # negative movie review\n",
    "# #positive user reiews, # negative user reviews\n",
    "movie_avg_train = np.zeros(len(train_value))\n",
    "user_avg_train = np.zeros(len(train_value))\n",
    "movie_revs_train = np.zeros(len(train_value))\n",
    "user_revs_train = np.zeros(len(train_value))\n",
    "# movie_pos_train = np.zeros(len(train_value))\n",
    "# user_pos_train = np.zeros(len(train_value))\n",
    "# movie_neg_train = np.zeros(len(train_value))\n",
    "# user_neg_train = np.zeros(len(train_value))\n",
    "\n",
    "for i in range(len(train_value)):\n",
    "    movie_avg_train[i] = movie_avg[train_movie[i]]\n",
    "    user_avg_train[i] = user_avg[train_user[i]]\n",
    "    movie_revs_train[i] = movie_revs[train_movie[i]]\n",
    "    user_revs_train[i] = user_revs[train_user[i]]\n",
    "#     movie_pos_train[i] = movie_pos[train_moive[i]]\n",
    "#     user_pos_train[i] = user_pos[train_user[i]]\n",
    "#     movie_neg_train[i] = movie_neg[train_movie[i]]\n",
    "#     user_neg_train[i] = user_neg[train_movie[i]]\n",
    "\n",
    "# features_train = np.vstack((movie_avg_train, user_avg_train, movie_revs_train, user_revs_train,\n",
    "#                             movie_pos_train, user_pos_train, movie_neg_train, user_neg_train)).T\n",
    "\n",
    "features_train = np.vstack((movie_avg_train, user_avg_train, movie_revs_train, user_revs_train)).T\n",
    "\n",
    "\n",
    "movie_avg_test = np.zeros(len(test_value))\n",
    "user_avg_test = np.zeros(len(test_value))\n",
    "movie_revs_test = np.zeros(len(test_value))\n",
    "user_revs_test = np.zeros(len(test_value))\n",
    "user_revs_test = np.zeros(len(test_value))\n",
    "# movie_pos_test = np.zeros(len(test_value))\n",
    "# user_pos_test = np.zeros(len(test_value))\n",
    "# movie_neg_test = np.zeros(len(test_value))\n",
    "# user_neg_test = np.zeros(len(test_value))\n",
    "\n",
    "for i in range(len(test_value)):\n",
    "    movie_avg_test[i] = movie_avg[test_movie[i]]\n",
    "    user_avg_test[i] = user_avg[test_user[i]]\n",
    "    movie_revs_test[i] = movie_revs[test_movie[i]]\n",
    "    user_revs_test[i] = user_revs[test_user[i]]\n",
    "#     movie_pos_test[i] = movie_pos[test_moive[i]]\n",
    "#     user_pos_test[i] = user_pos[test_user[i]]\n",
    "#     movie_neg_test[i] = movie_neg[test_movie[i]]\n",
    "#     user_neg_test[i] = user_neg[test_movie[i]]\n",
    "\n",
    "# features_test = np.vstack((movie_avg_test, user_avg_test, movie_revs_test, user_revs_test,\n",
    "#                            movie_pos_test, user_pos_test, movie_neg_test, user_neg_test)).T\n",
    "features_test = np.vstack((movie_avg_test, user_avg_test, movie_revs_test, user_revs_test)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE(predictions, test_set):\n",
    "    summation = 0\n",
    "    for i in range(len(predictions)):\n",
    "        summation += (predictions[i] - test_set[i])**2\n",
    "    return summation/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE_non_zero(predictions, test_set):\n",
    "    summation = 0\n",
    "    non_zero = 0\n",
    "    for i in range(len(predictions)):\n",
    "        value = test_set[i]\n",
    "        if value > 0:\n",
    "            summation += (predictions[i] - value)**2\n",
    "            non_zero += 1\n",
    "    return summation/non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0295266520192\n",
      "0.0292378472977\n",
      "13.4983016894\n",
      "13.2433637058\n"
     ]
    }
   ],
   "source": [
    "print MSE(movie_avg_test, test_value)\n",
    "print MSE(user_avg_test, test_value)\n",
    "print MSE_non_zero(movie_avg_test, test_value)\n",
    "print MSE_non_zero(user_avg_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(features_train, train_value)\n",
    "predictions = lr.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0469320084328\n"
     ]
    }
   ],
   "source": [
    "print lr.score(features_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0286764894139\n",
      "12.7348214851\n"
     ]
    }
   ],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(features_train, train_value)\n",
    "predictions = ridge.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0469322475302\n"
     ]
    }
   ],
   "source": [
    "print ridge.score(features_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0286764822202\n",
      "12.7348664267\n"
     ]
    }
   ],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(features_train, train_value)\n",
    "predictions = lasso.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0295029533853\n",
      "13.7036123355\n"
     ]
    }
   ],
   "source": [
    "print MSE(predictions, test_value)\n",
    "print MSE_non_zero(predictions, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0194643381485\n"
     ]
    }
   ],
   "source": [
    "print lasso.score(features_test, test_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID    Year                          Name\n",
      "0   1  2003.0               Dinosaur Planet\n",
      "1   2  2004.0    Isle of Man TT 2004 Review\n",
      "2   3  1997.0                     Character\n",
      "3   4  1994.0  Paula Abdul's Get Up & Dance\n",
      "4   5  2004.0      The Rise and Fall of ECW\n"
     ]
    }
   ],
   "source": [
    "# This file consists of titles and release years associated with each ID\n",
    "movie_titles = pd.read_csv('movie_titles.txt', header = None, names = ['ID','Year','Name'])\n",
    "print(movie_titles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 100\n",
    "svd = TruncatedSVD(n_components = n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = svd.fit_transform(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "components = svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 100)\n"
     ]
    }
   ],
   "source": [
    "print Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=20, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusters = 20\n",
    "kmeans = KMeans(init='k-means++', n_init=10, n_clusters=clusters)\n",
    "kmeans.fit(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "similar_users_avg = np.zeros(5000)\n",
    "\n",
    "clusters = \n",
    "\n",
    "for i in range(len(test_value)):\n",
    "    label = labels[test_movie[i]]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
